# LLM Wrapper

A simple PHP library that provides a unified interface for interacting with various Large Language Models like OpenAI, Anthropic, and Google.

## Install

```bash
composer require labsllm/llm-wrapper
```

## Basic Usage

Sending a simple prompt to an LLM:

```php
// With prompt only
$execute = LabsLLM::text()
    ->using(new OpenAI('SK-***', 'gpt-4o-mini'))
    ->executePrompt('Your question here');

$response = $execute->getResponseData();

echo $response->response;
```

## Response Structure

The response returned by `getResponseData()` contains three main elements:

```php
$response = $execute->getResponseData();

// Text response from the model (string)
$response->response;

// Function/tool calls requested by the model (array)
$response->function_calls;

// Tools that were executed with their results (array)
$response->called_tools;
```

### Response Elements

1. **response**: The text response generated by the model. For example, "The current date is July 14, 2023".

2. **function_calls**: Contains information about any tools/functions the model requested to call, including:
   - `name`: The name of the function requested
   - `arguments`: The parameters sent to the function
   - `id`: Unique identifier for this function call

3. **called_tools**: Contains results of tools that were actually executed, including:
   - `name`: The tool name
   - `arguments`: What was passed to the tool
   - `response`: The output returned by the tool
   - `id`: Unique identifier matching the function call

## Continuing Conversations with Chat History

You can continue an existing conversation by providing a message history:

```php
// Create or load an existing message history
$messages = MessagesBag::create([
    Message::system('You are a helpful assistant that can answer questions.'),
    Message::user('Hello, how are you?'),
    Message::assistant('I\'m doing well! How can I help you today?')
]);

$execute = LabsLLM::text()
    ->using(new OpenAI('SK-***', 'gpt-4o'))
    ->executeChat($messages); // Use executeChat instead of executePrompt

$response = $execute->getResponseData();

echo $response->response;
```


## With System Instructions

You can include system instructions in your prompt with the `withSystemMessage` method:

```php
// With system instructions
$execute = LabsLLM::text()
    ->using(new OpenAI('SK-***', 'gpt-4o-mini'))
    ->withSystemMessage('You are a helpful assistant that can answer questions and help with tasks your name is John Doe.')
    ->executePrompt('What is your name?');

$response = $execute->getResponseData();

echo $response->response;
```

## Using Tools/Functions

You can define tools for the model to use:

### Simple Function Without Parameters

The simplest way to define a function is without any parameters:

```php
// Define a function with no parameters
$dateFunction = FunctionHelper::create('getDate', 'Get the current date')
    ->callable(function(array $arguments) {
        return 'Today is ' . date('Y-m-d');
    });

// Execute with the tool available
$execute = LabsLLM::text()
    ->addTool($dateFunction)
    ->withMaxSteps(1)
    ->using(new OpenAI('SK-***', 'gpt-4o'))
    ->executePrompt('What is today\'s date?');

$response = $execute->getResponseData();

echo "Text response: " . $response->response . PHP_EOL;
```

### Function With Parameters

For more complex use cases, you can define functions with parameters:

```php
// Define a function with parameters
$dateTimeFunction = FunctionHelper::create('getDateOrTime', 'Get data or time from the day')
    ->withParameter([
        new StringParameter('type', 'The type of data to get')
    ], ['type']) // Second array defines required parameters
    ->callable(function(array $arguments) {
        if ($arguments['type'] === 'date') {
            return 'Today\'s date is ' . date('Y-m-d');
        } else if ($arguments['type'] === 'time') {
            return 'Current time is ' . date('H:i:s');
        }
        return 'Invalid type requested';
    });

// Execute with the tool available
$execute = LabsLLM::text()
    ->addTool($dateTimeFunction)
    ->withMaxSteps(2)
    ->using(new OpenAI('SK-***', 'gpt-4o'))
    ->executePrompt('What time is it right now?');

$response = $execute->getResponseData();

// Access the complete response data
echo "Text response: " . $response->response . PHP_EOL;
echo "Tools called: " . count($response->called_tools) . PHP_EOL;

// You can inspect which tools were called and their responses
foreach ($response->called_tools as $tool) {
    echo "Called: " . $tool['name'] . " with argument type: " . $tool['arguments']['type'] . PHP_EOL;
    echo "Tool response: " . $tool['response']['response'] . PHP_EOL;
}
```

### Parameter Types

Currently, the library supports the following parameter types:

- **StringParameter**: For text values
  - `name`: The name of the parameter
  - `description`: The description of the parameter
  - `enum`: An array of allowed values for the parameter (optional but recommended)

  ```php
  new StringParameter('method', 'method to pay', ['card', 'money'])
  ```

- **NumberParameter**: For numeric values
  - `name`: The name of the parameter
  - `description`: The description of the parameter

  ```php
  new NumberParameter('age', 'age of the person')
  ```

- **BooleanParameter**: For boolean values
  - `name`: The name of the parameter
  - `description`: The description of the parameter

  ```php
  new BooleanParameter('isPaid', 'if the payment was made')
  ```

- **ArrayParameter**: For arrays
  - `name`: The name of the parameter
  - `description`: The description of the parameter
  - `items`: The type of the items in the array

  ```php
  new ArrayParameter('names', 'names of the people', items: new StringParameter('name', 'name of the person'))

More parameter types will be added in future releases.

### Important Notes About Functions

1. The callable function receives an associative array of arguments
2. Always return a string or an array that can be converted to JSON
3. Required parameters should be listed in the second array of the `withParameter` method
4. Multiple steps (recursive tool calls) can be enabled with `withMaxSteps(n)`

### Understanding maxSteps

By default, `maxSteps` is set to 1, which means:

1. The model will generate a response or call a tool
2. If a tool is called, it will be executed
3. The execution stops after the tool responds

When `maxSteps` is set to 1 (default):
- If the model calls a tool, `$response->response` will be empty
- `$response->called_tools` will contain the tool that was executed and its response
- The response from the tool will not be sent back to the model

When `maxSteps` is greater than 1:
- After a tool is executed, its result is sent back to the model
- The model can then generate a text response based on the tool result
- Or it can call another tool (chained tool calls)
- This continues until `maxSteps` is reached or the model provides a text response


## Provider Support Status

Legend:
- ✅ Supported
- 🚧 In Development
- 📅 Planned
- ❌ Not Supported

| Feature | OpenAI | Google | Anthropic |
|---------|--------|-----------|--------|
| Text Prompts | ✅ | 🚧 | 📅 |
| System Instructions | ✅ | 🚧 | 📅 |
| Chat | ✅ | 🚧 | 📅 |
| Tools/Functions | ✅ | 📅 | ❌ 
| Structure Output | 🚧 | 📅 | ❌ |
| Streaming | 🚧 | 📅 | ❌ |
| Embeddings | 📅 | ❌ | ❌ |
| Voice | 📅 | ❌ | ❌ |
| Image Generation | 📅 | ❌ | 📅 | 